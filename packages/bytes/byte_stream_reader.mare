:: This class provides convenience methods for reading data from a stream of
:: bytes that presents itself in the form of a byte buffer that extends
:: "to the right" over time (such as data coming from the network),
:: while reading logic follows along and chops off pieces "from the left"
:: side of the byte buffer after they have been successfully read.
::
:: This is distinguished from ByteStreamChunkedReader, which accepts data
:: in discrete chunks that arrive independently.
::
:: While reading, a "cursor" and a "marker" position are maintained,
:: with the former indicating the fully advanced position in the stream
:: and the latter indicating an earlier position in the stream that can
:: be used as the start of a token for tokenization, as well as for rewind.
:: Once both the cursor and marker have passed by a part of the stream,
:: it is not possible to read those bytes anymore, by design.
:: This allows bytes to pass out of scope and be eventually garbage collected.
::
:: A variety of convenience methods for reading and comparing the bytes of
:: a token are provided, with a token being defined as the sequence of bytes
:: between the marker (marking the start of the token) and the cursor
:: (indicating the end of the token). Once a token has been read, the caller
:: can advance the cursor forward and/or move the marker to the cursor position
:: as needed to continue parsing the stream and set up the next token to read.
::
:: When finished, the reader instance can be cleared to allow garbage collection
:: of the appended data, then it can be used again for the next stream.
:: Alternatively, garbage collection can happen in the midst of an ongoing
:: stream using the compact method to drop only bytes that are behind
:: both the marker and cursor, releasing bytes that cannot be read anymore.
:class ByteStreamReader
  :prop _data Array(U8): []
  :prop _offset USize: 0
  :prop _mark_offset USize: 0

  :: Reset this object back to an empty state so that it can be reused.
  :: All data held and all cursor and mark state will be dropped.
  ::
  :: If the cursor and marker were already at the end of the stream,
  :: there will be no change in visible behavior from the caller side,
  :: but it's still important to call this method to allow garbage collection.
  :fun ref clear
    @_data.clear
    @_offset = 0
    @_mark_offset = 0
    @

  :: Drop any bytes that have been passed by both the marker and cursor,
  :: allowing buffers to be garbage collected even in the middle of a stream.
  ::
  :: If at the end of a stream it is more efficient to call clear instead.
  // TODO: Implement the compact function
  // :fun ref compact
  //   // ...
  //   @

  // TODO: Figure out the right abstraction for allowing an IOCoreEngine
  // to add bytes into our internal data buffer while remaining safe for both.
  // That is, we need to isolate pointer-unsafe/FFI code to "io" package, but
  // we also need to prevent logic outside of ByteStreamReader from doing
  // anything here other than adding bytes to the end of the data stream
  // (we can't allow the caller to mutate the data arbitrarily).
  :fun ref "<<" (chunk Array(U8)'val)
    // TODO: zero copy here - implies chunk param needs to be consumed/extracted
    chunk.each -> (byte | @_data << byte)
    @

  :: Move the mark position to match the current cursor position.
  :: This is often used to mark the start of a token in a token stream,
  :: and to set a place to rewind back to in case of an interrupted stream.
  :fun ref mark_here
    @_mark_offset = @_offset
    @

  :: Move the cursor back to match the last marker position.
  :: This is often used to reset the stream to a known place when interrupted,
  :: so that when the next chunk is available it can be resumed from there.
  :fun ref rewind_to_marker
    @_offset = @_mark_offset
    @

  :: Get the number of bytes available in the stream ahead of the cursor.
  :: This the the number of bytes that can be peeked or advanced past.
  :: Attempting to go past that point in the stream will raise an error.
  :fun bytes_ahead: @_data.size - @_offset

  :: Get the number of bytes available in the stream ahead of the marker.
  :: This will always be equal to or greater than those ahead of the cursor.
  :fun bytes_ahead_of_marker: @_data.size - @_mark_offset

  :: Get the number of bytes in the currently marked token.
  :: That is, the number of bytes between the marker and the cursor.
  :fun token_byte_size: @_offset - @_mark_offset

  :: Yield each byte in the currently marked token.
  :: That is, the bytes between the marker and the cursor.
  :fun each_token_byte None
    :yields U8 for None
    @each_token_byte_until -> (byte | (yield byte), False)
    None

  :: Yield each byte in the currently marked token until the block returns True.
  :: Returns True if the block stopped iteration early by returning True.
  :: Otherwise returns False, indicating that iteration fully completed.
  :fun each_token_byte_until Bool
    :yields U8 for Bool
    @_data.each_until(@_mark_offset, @_offset) -> (byte | yield byte)

  :: For the bytes in the currently marked token, yield each associated chunk,
  :: along with the start and end offset of the chunk that are within the token.
  :: This is used internally for chunk-wise comparison and copying operations.
  :fun _each_token_slice None
    :yields for None // TODO: unify Array cap with ByteStreamChunkedReader signature?
    yield (@_data, @_mark_offset, @_offset)

  :: Same as the each_token_byte function, but allows the yield block to return
  :: True to stop iteration early, and in such a case the function returns True.
  :fun _each_token_slice_until Bool
    :yields for Bool // TODO: unify Array cap with ByteStreamChunkedReader signature?
    yield (@_data, @_mark_offset, @_offset)

  :: Return True if the bytes in the currently marked token are equivalent
  :: to the bytes referenced by the given string.
  :fun is_token_equal_to (other String)
    @token_byte_size == other.size && (
      other_start USize = 0
      unequal = @_each_token_slice_until -> (chunk, start, end |
        slice_size = end - start

        unequal_slice = String
          .from_array(chunk.clone()) // TODO: no clone here
          .is_byte_slice_equal(start, other, other_start, slice_size)
          .not

        other_start += slice_size
        unequal_slice
      )
      unequal.invert
    )

  :: Return True if the bytes in the currently marked token, after lowercasing
  :: any encountered ASCII letters (A-Z) are equivalent to the given string.
  :: That is, the given string should be supplied as already being lowercase.
  :fun is_token_ascii_lowercase_equal_to (other String)
    @token_byte_size == other.size && (
      index USize = 0
      unequal = @each_token_byte_until -> (byte |
        lower_byte = if (byte >= 'A' && byte <= 'Z') (byte - 'A' + 'a' | byte)
        unequal_byte = try (lower_byte != other[index]! | True)
        index += 1
        unequal_byte
      )
      unequal.invert
    )

  // TODO: Add way to chop/extract a token instead of copying it.

  :: Return the portion of the stream between the marker and the cursor,
  :: as an immutable String.
  :fun token_as_string String
    :: TODO: Don't copy, or at least do a more efficient copy.
    // TODO: explicit variable type should not be needed in this line:
    string String'iso = String.new_iso(@token_byte_size)
    @each_token_byte -> (byte | string.push_byte(byte))
    --string

  :: Return the portion of the stream between the marker and the cursor,
  :: parsed as a positive integer written with sequential decimal digits (0-9).
  :: If other (non-digit) bytes are encountered, an error is raised.
  :fun token_as_positive_integer! U64
    value U64 = 0
    error = False
    @each_token_byte_until -> (byte |
      if (byte >= '0' && byte <= '9') (
        value = value * 10 + (byte - '0').u64
        False // continue iterating
      |
        error = True // TODO: should we just raise an error here directly?
        True // stop iteration
      )
    )
    if error error!
    value

  :: Return the byte value that is N bytes ahead, without moving the cursor.
  :: Raises an error if there are not enough bytes to do so.
  :fun peek_byte! (n USize = 0) U8
    @_data[@_offset + n]!

  :: Advance the cursor forward to the end of the byte stream.
  :fun ref advance_to_end
    @_offset = @_data.size
    @

  :: Advance the cursor forward in the byte stream by N total bytes.
  :: Raises an error if there are not enough bytes to do so, leaving the cursor
  :: pointing to the next future byte that will arrive in the byte stream.
  :fun ref advance! (n USize)
    @_offset += n
    if (@_offset > @_data.size) (
      @_offset = @_data.size
      error!
    )
    @

  :: Advance the cursor byte-by-byte for as long as the block yields True,
  :: stopping the cursor pointing at the byte for which it yielded False.
  :: Raises an error if the end of the byte stream is reached prior to that.
  :fun ref advance_while!
    :yields U8 for Bool
    while (yield @_data[@_offset]!) (@_offset += 1)
    @
